{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_dict = [\n",
    "'into_the_wild',\n",
    "'rush_hour_3',\n",
    "'avengers_age_of_ultron',\n",
    "'spiderman_3',\n",
    "'mad_max_fury_road',\n",
    "'zootopia',\n",
    "'ratatouille',\n",
    "'tomorrowland_2015',\n",
    "'nightcrawler',\n",
    "'2012',\n",
    "'21-jump-street-2011',\n",
    "'shawshank_redemption',\n",
    "'1010792-its_a_wonderful_life',\n",
    "'hugo',\n",
    "'live_die_repeat_edge_of_tomorrow',\n",
    "'the_choice',\n",
    "'wonder_woman_2017',\n",
    "'10011582-TRON_legacy',\n",
    "'taken',\n",
    "'it_2017',\n",
    "'equilibrium',\n",
    "'awake',\n",
    "'300',\n",
    "'real_steel',\n",
    "'the_dark_knight_rises',\n",
    "'pirates_of_the_caribbean_3',\n",
    "'the_hateful_eight',\n",
    "'lost_world_jurassic_park',\n",
    "'10010662-my_sisters_keeper',\n",
    "'la_la_land',\n",
    "'scott_pilgrims_vs_the_world',\n",
    "'donnie_darko',\n",
    "'the_perks_of_being_a_wallflower',\n",
    "'godfather_part_ii',\n",
    "'frozen_2013',\n",
    "'cars_3',\n",
    "'wrong_turn',\n",
    "'1198124-shutter_island',\n",
    "'italian_job',\n",
    "'oceans_twelve',\n",
    "'annabelle_creation',\n",
    "'the_conjuring_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR CRITIC REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### For critic reviews\n",
    "for i in range(0,len(movies_dict)):\n",
    "        url = \"https://www.rottentomatoes.com\" \n",
    "        url = url + '/m/' + movies_dict[i] + '/reviews/?type=top_critics'\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"lxml\")\n",
    "        x = len(soup.find_all(class_ = 'the_review'))\n",
    "        movie_name = np.repeat(movies_dict[i].replace('_',' '),x)\n",
    "        top_critic = [soup.find_all(class_= 'the_review')[j].get_text().lstrip().rstrip() for j in range(0,len(soup.find_all(class_ = 'the_review')))]\n",
    "        d = {'movie_name': movie_name, 'top_critic': top_critic}\n",
    "        test = pd.DataFrame(data=d)\n",
    "        df = df.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR AUDIENCE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(movies_dict)):\n",
    "    for a in range(1,26):\n",
    "        url = \"https://www.rottentomatoes.com\" \n",
    "        url = url + '/m/' + movies_dict[i] + '/reviews/?page=' + str(a) + '&type=user&sort='\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"lxml\")\n",
    "        x = len(soup.find_all(class_ = 'user_review'))\n",
    "        movie_name = np.repeat(movies_dict[i].replace('_',' '),x)\n",
    "        top_critic = [soup.find_all(class_= 'user_review')[j].get_text().lstrip().rstrip() for j in range(0,len(soup.find_all(class_ = 'user_review')))]\n",
    "        d = {'movie_name': movie_name, 'top_critic': top_critic}\n",
    "        test = pd.DataFrame(data=d)\n",
    "        df = df.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR MOVIE RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### for ratings\n",
    "for i in range(0,len(movies_dict)):\n",
    "    url = \"https://www.rottentomatoes.com\" \n",
    "    url = url + '/m/' + movies_dict[i]\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    movie_name = movies_dict[i].replace('_',' ')\n",
    "    critic_rating = soup.find('div',attrs = {'id':'scoreStats'}).text.lstrip().replace('\\n','').replace(' ','')[14:17]\n",
    "    audience_rating = soup.find('div',attrs= {'class':'audience-info hidden-xs superPageFontColor'}).text.lstrip().replace('\\n','').replace(' ','')[14:17]\n",
    "    movie_type = soup.find_all('div',attrs = {'class':'meta-value'})[0].text\n",
    "    genre = soup.find_all('div',attrs = {'class':'meta-value'})[1].text.replace('\\n','').replace(' ','')\n",
    "    director = soup.find_all('div',attrs = {'class':'meta-value'})[2].text.replace('\\n','')\n",
    "    boxoffice_collection = soup.find_all('div',attrs = {'class':'meta-value'})[6].text.replace('\\n','').replace(',','').replace('$','')\n",
    "    d_values = [(movie_name,critic_rating,audience_rating,movie_type,genre,director,boxoffice_collection)]\n",
    "    d_labels = ['movie_name','critic_rating','audience_rating','movie_type','genre','director','boxoffice_collection']\n",
    "    test = pd.DataFrame(d_values,columns=d_labels)\n",
    "    df = df.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD FREQUENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv('ratings_critics_review.csv',encoding = 'ISO-8859-1')\n",
    "orig_data['top_critic']=orig_data['top_critic'].str.lower()\n",
    "orig_data['top_critic']=orig_data['top_critic'].astype(str)\n",
    "for i in range(len(orig_data)):    \n",
    "    words = re.findall(r\"\\w+\",orig_data['top_critic'][i])\n",
    "    orig_data['top_critic'][i]= set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_data['top_critic'] = orig_data['top_critic'].apply(list)\n",
    "final = orig_data.groupby('movie_name').agg(lambda x: x.tolist())\n",
    "final.reset_index(inplace = True)\n",
    "for i in range(len(final)):\n",
    "    final['top_critic'][i] = list(itertools.chain(*final['top_critic'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') + list(string.punctuation)\n",
    "for j in range(len(final)):\n",
    "    final['top_critic'][j] = [i for i in final['top_critic'][j] if i not in stop]\n",
    "    final['top_critic'][j] = list(map(lemmatizer.lemmatize, final['top_critic'][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_rev = final.loc[(final['movie_name'] == 'the dark knight rises') | (final['movie_name'] == 'avengers age of ultron')\n",
    "| (final['movie_name'] == 'wonder woman 2017') | (final['movie_name'] == 'frozen 2013') | (final['movie_name'] == 'zootopia')\n",
    "| (final['movie_name'] == 'it 2017') | (final['movie_name'] == '300') | (final['movie_name'] == '21-jump-street-2011')\n",
    "| (final['movie_name'] == 'mad max fury road')  | (final['movie_name'] == '1198124-shutter island')]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "critic = pd.read_csv('Critic reviews.csv',encoding = \"ISO-8859-1\")\n",
    "critic_rev = critic['Critic reviews']\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(critic_rev)):\n",
    "    sentscore = analyzer.polarity_scores(critic_rev[i])\n",
    "    review = critic_rev[i]\n",
    "    #d = {'review': review, 'sentscore': str(sentscore[\"compound\"])}\n",
    "    d_values = [(review,str(sentscore[\"compound\"]))]\n",
    "    d_labels = ['review','sentscore']\n",
    "    test = pd.DataFrame(d_values, columns = d_labels)\n",
    "    df = df.append(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
